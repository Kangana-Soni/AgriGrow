# -*- coding: utf-8 -*-
"""Fertilizer_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eaiWMqIw9kjuc7qXSOADwJTLP2DqIBc4

# New Section
"""

#!/usr/bin/env python
# coding: utf-8

# In[1]:


#importing library
import numpy as np
import pandas as pd


# In[2]:


#read dataset
data = pd.read_csv('/Fertilizer_Prediction.csv')


# In[3]:


#data analysis
print(data.head(5))


# In[4]:


data.tail(5)


# In[5]:


data.shape


# In[6]:


data['Fertilizer Name'].value_counts()


# In[7]:


data.info()


# In[8]:


data.corr()


# In[9]:


data.describe()


# In[10]:


data.isnull().sum()


# In[11]:


data.nunique()


# In[12]:


data['Fertilizer Name'].nunique()


# In[13]:


data['Fertilizer Name']=data['Fertilizer Name'].replace({'Urea':0,'DAP':1,'28-28':2,'14-35-14':3,'20-20':4,'17-17-17':5,'10-26-26':6})
data[25:50]


# In[26]:


print(data['Fertilizer Name'].unique())


# In[27]:


data['Crop Type'].nunique()


# In[28]:


data['Crop Type']=data['Crop Type'].replace({'Maize':0,'Ground Nuts':1,'Paddy':2,'Oil seeds':3,'Wheat':4,'Barley':5,'Tobacco':6,'Pulses':7,'Millets':8,'Sugarcane':9,'Cotton':10})
from sklearn.preprocessing import LabelEncoder
ls=LabelEncoder()


# In[29]:


print(data['Crop Type'].unique())


# In[30]:


data['Soil Type'].nunique()


# In[31]:


data['Soil Type']=data['Soil Type'].replace({'Sandy':0,'Red':1,'Loamy':2,'Black':3,'Clayey':4})
from sklearn.preprocessing import LabelEncoder
ls=LabelEncoder()


# In[32]:


print(data['Soil Type'].unique())


# In[141]:
print(data)
print(data.info())


#defining x and y
x=data.iloc[:,0:8].values
y=data['Fertilizer Name'].values
x[:],y[:]

print(x)
print(y)
# In[142]:


#feature scaling
from sklearn.preprocessing import MinMaxScaler
mms=MinMaxScaler()
mmsx=mms.fit_transform(x)
print(mmsx[:4])
print(pd.DataFrame(mmsx).describe())


# In[143]:


#labelbinarizer
from keras.utils import np_utils
npy=np_utils.to_categorical(y)
print(npy[:5])


# In[144]:


#train_test_split
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(mmsx, npy, test_size = 0.4, random_state=50)


# In[145]:


print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)


# In[124]:


#importing libraries
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential 
from keras.layers import Dense,Activation
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy


# In[129]:


#building the model
model=Sequential()
model.add(Dense(90,input_dim=8,activation='relu'))
#hidden layer
model.add(Dense(160,activation='relu'))
#Output layer 
model.add(Dense(7,activation='softmax'))


# In[132]:


model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])


# In[133]:


model.summary()


# In[134]:


#model.fit(x_train,y_train,epochs=100)
model.fit(x_train, y_train, epochs=150, validation_data=(x_test, y_test))


# In[ ]:


pred_y=model.predict(x_test)
pred_y=np.argmax(pred_y,axis=1)
print(pred_y)
y_test=np.argmax(y_test,axis=1)

print(y_test)


# In[ ]:


from sklearn.metrics import classification_report,confusion_matrix,accuracy_score

print(classification_report(pred_y,y_test))
print(confusion_matrix(pred_y,y_test))
print(accuracy_score(pred_y,y_test))


# In[ ]:


x_test[0:1]

"""# New Section

# New Section
"""

